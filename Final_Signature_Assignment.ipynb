{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Student Initials', 'Age Range', 'Online Activity Type', 'Website', 'Date', 'Weekday', 'Time Start', 'Time End', 'Time on Activity', 'Title of Movie', ' TV Show OR Name of Item being shopped for', 'Was the media or item recommended by the site?', 'Were you just browsing?', 'Did you look/search for the specific media or item?', 'Genre of media (drama', ' horror', ' suspense', ' comedy', ' etc) OR Type of item (beauty', ' clothing', ' electronic', ' homegoods', ' etc)', 'Recommendation(s) Clicked']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your Excel file\n",
    "file_path = \"my_data.csv\"  # Replace with your actual file path\n",
    "data = pd.read_csv(file_path)  # Read the Excel file\n",
    "\n",
    "# Display the columns\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['Student Initials', 'Age Range', 'Online Activity Type', 'Website', 'Date', 'Weekday', 'Time Start', 'Time End', 'Time on Activity', 'Title of Movie', 'TV Show OR Name of Item being shopped for', 'Was the media or item recommended by the site?', 'Were you just browsing?', 'Did you look/search for the specific media or item?', 'Genre of media (drama', 'horror', 'suspense', 'comedy', 'etc) OR Type of item (beauty', 'clothing', 'electronic', 'homegoods', 'etc)', 'Recommendation(s) Clicked']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned data from an Excel file\n",
    "file_path = \"my_data.csv\"  # Update with the correct path if needed\n",
    "data = pd.read_csv(file_path)  # Read the Excel file\n",
    "\n",
    "# Optional: Strip whitespace from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Display the columns in the dataset\n",
    "print(\"Column Names:\", data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['Student Initials', 'Age Range', 'Online Activity Type', 'Website', 'Date', 'Weekday', 'Time Start', 'Time End', 'Time on Activity', 'Title of Movie', 'TV Show OR Name of Item being shopped for', 'Was the media or item recommended by the site?', 'Were you just browsing?', 'Did you look/search for the specific media or item?', 'Genre of media (drama', 'horror', 'suspense', 'comedy', 'etc) OR Type of item (beauty', 'clothing', 'electronic', 'homegoods', 'etc)', 'Recommendation(s) Clicked']\n",
      "\n",
      "Dataset Information:\n",
      "Number of rows: 10\n",
      "Number of columns: 24\n",
      "\n",
      "Column Data Types:\n",
      "Student Initials                                        object\n",
      "Age Range                                               object\n",
      "Online Activity Type                                    object\n",
      "Website                                                 object\n",
      "Date                                                    object\n",
      "Weekday                                                 object\n",
      "Time Start                                              object\n",
      "Time End                                                object\n",
      "Time on Activity                                        object\n",
      "Title of Movie                                          object\n",
      "TV Show OR Name of Item being shopped for               object\n",
      "Was the media or item recommended by the site?          object\n",
      "Were you just browsing?                                 object\n",
      "Did you look/search for the specific media or item?     object\n",
      "Genre of media (drama                                    int64\n",
      "horror                                                 float64\n",
      "suspense                                               float64\n",
      "comedy                                                 float64\n",
      "etc) OR Type of item (beauty                           float64\n",
      "clothing                                               float64\n",
      "electronic                                             float64\n",
      "homegoods                                              float64\n",
      "etc)                                                   float64\n",
      "Recommendation(s) Clicked                              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"my_data.csv\"\n",
    "try:\n",
    "    # Use read_excel for Excel files\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Optional: Strip whitespace from column names\n",
    "    data.columns = data.columns.str.strip()\n",
    "\n",
    "    # Display the columns in the dataset\n",
    "    print(\"Column Names:\", data.columns.tolist())\n",
    "\n",
    "    # Additional basic information about the dataset\n",
    "    print(\"\\nDataset Information:\")\n",
    "    print(\"Number of rows:\", len(data))\n",
    "    print(\"Number of columns:\", len(data.columns))\n",
    "\n",
    "    # Quick overview of the data types\n",
    "    print(\"\\nColumn Data Types:\")\n",
    "    print(data.dtypes)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: No data in the file {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student Initials Age Range Online Activity Type      Website        Date  \\\n",
      "0               MR     52-56      Online Shopping       Amazon  11/16/2024   \n",
      "1               MR     52-56   Movie/TV Streaming      Netflix  11/16/2024   \n",
      "2               MR     52-56      Online Shopping         Etsy  11/17/2024   \n",
      "3               MR     52-56   Movie/TV Streaming      YouTube  11/17/2024   \n",
      "4               MR     52-56   Movie/TV Streaming  Disney Plus  11/18/2024   \n",
      "\n",
      "    Weekday Time Start  Time End Time on Activity           Title of Movie  \\\n",
      "0    Friday    9:00 AM   9:30 AM          30 mins          Gardening tools   \n",
      "1    Friday    8:00 PM  10:00 PM          2 hours                The Crown   \n",
      "2  Saturday   11:00 AM  11:20 AM          20 mins  Handmade candle holders   \n",
      "3  Saturday    7:30 PM   9:00 PM        1.5 hours      Gardening tutorials   \n",
      "4    Sunday    6:30 PM   9:00 PM        2.5 hours                 Hamilton   \n",
      "\n",
      "   ... Genre of media (drama horror suspense comedy  \\\n",
      "0  ...                     3    NaN      NaN    NaN   \n",
      "1  ...                     0    NaN      NaN    NaN   \n",
      "2  ...                     2    NaN      NaN    NaN   \n",
      "3  ...                     1    NaN      NaN    NaN   \n",
      "4  ...                     0    NaN      NaN    NaN   \n",
      "\n",
      "   etc) OR Type of item (beauty  clothing  electronic  homegoods  etc)  \\\n",
      "0                           NaN       NaN         NaN        NaN   NaN   \n",
      "1                           NaN       NaN         NaN        NaN   NaN   \n",
      "2                           NaN       NaN         NaN        NaN   NaN   \n",
      "3                           NaN       NaN         NaN        NaN   NaN   \n",
      "4                           NaN       NaN         NaN        NaN   NaN   \n",
      "\n",
      "   Recommendation(s) Clicked  \n",
      "0                        NaN  \n",
      "1                        NaN  \n",
      "2                        NaN  \n",
      "3                        NaN  \n",
      "4                        NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Column Names: ['Student Initials', 'Age Range', 'Online Activity Type', 'Website', 'Date', 'Weekday', 'Time Start', 'Time End', 'Time on Activity', 'Title of Movie', 'TV Show OR Name of Item being shopped for', 'Was the media or item recommended by the site?', 'Were you just browsing?', 'Did you look/search for the specific media or item?', 'Genre of media (drama', 'horror', 'suspense', 'comedy', 'etc) OR Type of item (beauty', 'clothing', 'electronic', 'homegoods', 'etc)', 'Recommendation(s) Clicked']\n",
      "Column 'Recommendation Clicked' is missing.\n",
      "Average Time per Student: 745.00 minutes\n",
      "Activity Frequency per Student: 10.00 activities\n",
      "Recommendations Clicked Rate: 0.0000 recommendations per minute\n",
      "Duration Summary Statistics:\n",
      "count     10.000000\n",
      "mean      74.500000\n",
      "std       54.285766\n",
      "min       20.000000\n",
      "25%       30.000000\n",
      "50%       60.000000\n",
      "75%      116.250000\n",
      "max      150.000000\n",
      "Name: Duration (minutes), dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MLuca\\AppData\\Local\\Temp\\ipykernel_59952\\1605138246.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Time Start'] = pd.to_datetime(data['Time Start'], errors='coerce')\n",
      "C:\\Users\\MLuca\\AppData\\Local\\Temp\\ipykernel_59952\\1605138246.py:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Time End'] = pd.to_datetime(data['Time End'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned data from an Excel file\n",
    "file_path = \"my_data.csv\"  # Update with the correct path if needed\n",
    "data = pd.read_csv(file_path)  # Read the Excel file\n",
    "\n",
    "# Strip whitespace from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Display the first few rows and column names\n",
    "print(data.head())\n",
    "print(\"Column Names:\", data.columns.tolist())  # Check the actual column names\n",
    "\n",
    "# Check for 'Time Start' and 'Time End' columns and calculate 'Duration (minutes)'\n",
    "if 'Time Start' in data.columns and 'Time End' in data.columns:\n",
    "    # Convert 'Time Start' and 'Time End' to datetime\n",
    "    data['Time Start'] = pd.to_datetime(data['Time Start'], errors='coerce')\n",
    "    data['Time End'] = pd.to_datetime(data['Time End'], errors='coerce')\n",
    "    \n",
    "    # Calculate duration in minutes\n",
    "    data['Duration (minutes)'] = (data['Time End'] - data['Time Start']).dt.total_seconds() / 60\n",
    "else:\n",
    "    print(\"Time Start or Time End columns are missing.\")\n",
    "\n",
    "# Calculate Total Duration\n",
    "total_duration = data['Duration (minutes)'].sum() if 'Duration (minutes)' in data.columns else 0\n",
    "\n",
    "# Check if 'Student Initials' column exists\n",
    "if 'Student Initials' in data.columns:\n",
    "    # Calculate Unique Students\n",
    "    unique_students = data['Student Initials'].nunique()\n",
    "else:\n",
    "    print(\"Column 'Student Initials' is missing.\")\n",
    "    unique_students = 0  # Set to 0 or handle accordingly\n",
    "\n",
    "# Calculate Total Activities\n",
    "total_activities = data.shape[0]\n",
    "\n",
    "# Check for 'Recommendation Clicked' and calculate total\n",
    "if 'Recommendation Clicked' in data.columns:\n",
    "    # Convert 'Recommendation Clicked' to numeric, handling errors\n",
    "    data['Recommendation Clicked'] = pd.to_numeric(data['Recommendation Clicked'], errors='coerce')\n",
    "    total_recommendations_clicked = data['Recommendation Clicked'].sum()\n",
    "else:\n",
    "    print(\"Column 'Recommendation Clicked' is missing.\")\n",
    "    total_recommendations_clicked = 0\n",
    "\n",
    "# 1. Average Time Spent on Activities per Student\n",
    "average_time_per_student = total_duration / unique_students if unique_students > 0 else 0\n",
    "print(f'Average Time per Student: {average_time_per_student:.2f} minutes')\n",
    "\n",
    "# 2. Activity Frequency per Student\n",
    "frequency_per_student = total_activities / unique_students if unique_students > 0 else 0\n",
    "print(f'Activity Frequency per Student: {frequency_per_student:.2f} activities')\n",
    "\n",
    "# 3. Recommendations Clicked Rate\n",
    "recommendations_clicked_rate = total_recommendations_clicked / total_duration if total_duration > 0 else 0\n",
    "print(f'Recommendations Clicked Rate: {recommendations_clicked_rate:.4f} recommendations per minute')\n",
    "\n",
    "# Optional: Print summary statistics for duration\n",
    "if 'Duration (minutes)' in data.columns:\n",
    "    print(\"Duration Summary Statistics:\")\n",
    "    print(data['Duration (minutes)'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Recommendations Clicked' not found. Recommendations Clicked calculations skipped.\n",
      "Average Time per Student: 745.00 minutes\n",
      "Activity Frequency per Student: 10.00 activities\n",
      "Recommendations Clicked Rate: 0.0000 recommendations per minute\n",
      "Duration Summary Statistics:\n",
      "count     10.000000\n",
      "mean      74.500000\n",
      "std       54.285766\n",
      "min       20.000000\n",
      "25%       30.000000\n",
      "50%       60.000000\n",
      "75%      116.250000\n",
      "max      150.000000\n",
      "Name: Duration (minutes), dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MLuca\\AppData\\Local\\Temp\\ipykernel_59952\\1378974642.py:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Time Start'] = pd.to_datetime(data['Time Start'], errors='coerce')\n",
      "C:\\Users\\MLuca\\AppData\\Local\\Temp\\ipykernel_59952\\1378974642.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Time End'] = pd.to_datetime(data['Time End'], errors='coerce')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Activity Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 64\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration (minutes)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Visualizations\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Bar Chart: Total time spent per Activity Type\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m activity_time \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mActivity Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration (minutes)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     65\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     66\u001b[0m activity_time\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MLuca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MLuca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\MLuca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Activity Type'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"my_data.csv\"  # Update with the correct path if needed\n",
    "\n",
    "# Check if 'Activity Type' column exists before reading the CSV\n",
    "if 'Activity Type' not in pd.read_csv(file_path, nrows=0, header=0):\n",
    "    print(\"'Activity Type' column not found in the CSV. Skipping visualizations that rely on it.\")\n",
    "    data = pd.read_csv(file_path)\n",
    "else:\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "# Shorten the recommendations column name (recommended)\n",
    "recommendations_column = \"Recommendations Clicked\"  # Replace with your desired shorter name\n",
    "\n",
    "# Alternatively, use `.get()` with a default value (optional)\n",
    "# recommendations_column = data.get(\"Recommendation(s) Clicked: how many of the site's recommendations did you click through before making a selection or stopping activity?\", default=0)\n",
    "\n",
    "# Convert 'Time Start' and 'Time End' to datetime (if necessary)\n",
    "if data['Time Start'].dtype == 'object' and data['Time End'].dtype == 'object':\n",
    "    data['Time Start'] = pd.to_datetime(data['Time Start'], errors='coerce')\n",
    "    data['Time End'] = pd.to_datetime(data['Time End'], errors='coerce')\n",
    "\n",
    "# Calculate Duration in minutes\n",
    "data['Duration (minutes)'] = (data['Time End'] - data['Time Start']).dt.total_seconds() / 60\n",
    "\n",
    "# Calculate Total Duration\n",
    "total_duration = data['Duration (minutes)'].sum()\n",
    "\n",
    "# Calculate Unique Students (assuming 'Student Initials' column exists)\n",
    "if 'Student Initials' in data.columns:\n",
    "    unique_students = data['Student Initials'].nunique()\n",
    "else:\n",
    "    print(\"Column 'Student Initials' is missing. Cannot calculate unique students.\")\n",
    "    unique_students = 0\n",
    "\n",
    "# Calculate Total Activities\n",
    "total_activities = data.shape[0]\n",
    "\n",
    "# Calculate Total Recommendations Clicked\n",
    "# Ensure recommendations column exists before accessing it\n",
    "if recommendations_column in data.columns:\n",
    "    total_recommendations_clicked = data[recommendations_column].sum()\n",
    "else:\n",
    "    print(f\"Column '{recommendations_column}' not found. Recommendations Clicked calculations skipped.\")\n",
    "    total_recommendations_clicked = 0\n",
    "\n",
    "# 1. Average Time Spent on Activities per Student\n",
    "average_time_per_student = total_duration / unique_students if unique_students > 0 else 0\n",
    "print(f'Average Time per Student: {average_time_per_student:.2f} minutes')\n",
    "\n",
    "# 2. Activity Frequency per Student\n",
    "frequency_per_student = total_activities / unique_students if unique_students > 0 else 0\n",
    "print(f'Activity Frequency per Student: {frequency_per_student:.2f} activities')\n",
    "\n",
    "# 3. Recommendations Clicked Rate (if applicable)\n",
    "recommendations_clicked_rate = total_recommendations_clicked / total_duration if total_duration > 0 else 0\n",
    "print(f'Recommendations Clicked Rate: {recommendations_clicked_rate:.4f} recommendations per minute')\n",
    "\n",
    "# Optional: Print summary statistics for duration\n",
    "print(\"Duration Summary Statistics:\")\n",
    "print(data['Duration (minutes)'].describe())\n",
    "\n",
    "# Visualizations\n",
    "\n",
    "# Bar Chart: Total time spent per Activity Type\n",
    "activity_time = data.groupby('Activity Type')['Duration (minutes)'].sum()\n",
    "plt.figure(figsize=(10, 6))\n",
    "activity_time.plot(kind='bar', color='skyblue')\n",
    "plt.title('Total Time Spent per Activity Type')\n",
    "plt.ylabel('Total Duration (minutes)')\n",
    "plt.xlabel('Activity Type')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pie Chart: Distribution of Activity Types\n",
    "plt.figure(figsize=(12, 7))\n",
    "activity_counts = data['Activity Type'].value_counts()\n",
    "colors = sns.color_palette(\"pastel\")\n",
    "\n",
    "# Create the pie chart without labels\n",
    "wedges, _ = plt.pie(activity_counts, colors=colors, autopct=None, labels=None)\n",
    "\n",
    "plt.title('Distribution of Activity Types')\n",
    "\n",
    "# Create a legend on the side\n",
    "plt.legend(wedges, activity_counts.index, \n",
    "           title=\"Activity Types\", \n",
    "           loc=\"center left\", \n",
    "           bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot: Recommendations clicked vs. duration (Ensuring column exists)\n",
    "if recommendations_column in data.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        data=data, \n",
    "        x='Duration (minutes)', \n",
    "        y=recommendations_column,  # Use the chosen column name\n",
    "        hue='Activity Type', \n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('Recommendations Clicked vs. Duration')\n",
    "    plt.xlabel('Duration (minutes)')\n",
    "    plt.ylabel('Recommendations Clicked')\n",
    "    plt.legend(title='Activity Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{recommendations_column}' not found. Scatter plot not generated.\")\n",
    "\n",
    "# Histogram: Duration distribution for activities\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Duration (minutes)'].dropna(), bins=10, kde=True, color='purple')\n",
    "plt.title('Duration Distribution for Activities')\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
